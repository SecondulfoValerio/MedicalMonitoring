# -*- coding: utf-8 -*-
"""ModelloMedicalMonitoring.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11PZuameLLhthN601UNF5A4AsuUhQEw8b
"""

!pip install pandas

import pandas as pd # read the data

df = pd.read_csv('/content/heart.csv',sep=",")  #csv heart file
df.head() #show the 5 first rows of the dataset

import seaborn as sb
import matplotlib.pyplot as plt
#correlation matrix
sb.set(style="white")
plt.rcParams['figure.figsize']=(25,25)
sb.heatmap(df.corr('spearman',True),annot= True, linewidth=0.5)
plt.title("Correlation between variables")

#drop values
df2_ext_f=df.iloc[:, [0, 2, 4, 7]]
df2_ext_f.head()

from keras.utils import to_categorical

labels = to_categorical(df.pop('target')) #Create classes from the labels

import numpy as np #import numpy library, used for arithmetic
df2_ext_f=df.iloc[:, [0, 2, 4, 7]]

features = np.array(df2_ext_f) #convert our dataframe into ndarray, only array type that neural network takes as input

features

labels

from sklearn.model_selection import train_test_split


#Split the dataset into training set 85% and test set 15%
train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.15,shuffle=True)

import tensorflow as tf

from tensorflow.keras.layers import Dense, Activation

#Parameters for the training :
NB_classes = 2 #number of outputs - number of classes 2: Normal / Desease
NB_neurones = 40 #main number of neurones
NB_features = 4 #number of inputs
activation_func = tf.keras.activations.sigmoid #activation function used

#Densly connected neural network
model = tf.keras.Sequential([
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func,input_shape=(NB_features,)),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dense(NB_neurones,activation=activation_func),
                             tf.keras.layers.Dropout(0.1), #drop randomly some connection to avoid overfiting
                             #softmax will output an array containing probabilities of each classes
                             #the highest one is the predicted class
                             tf.keras.layers.Dense(NB_classes,activation=tf.keras.activations.softmax)
])

model.compile(optimizer="adam",loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy']) #compile the model

model.summary() #to see the paramter of our model

#training
model.fit(x=train_features,
          y=train_labels,
          epochs=80,
          validation_data=(test_features,test_labels),
          verbose=1,
          shuffle=True) #Train our model

#model performance evaluation
performance=model.evaluate(test_features,test_labels, batch_size=32, verbose=1, steps=None, )[1] * 100
print('Final accuracy : ', round(performance), '%')

!pip install emlearn

#model .h file creation
import emlearn

path = 'heart.h'

cmodel = emlearn.convert(model, method='inline')

cmodel.save(file=path, name='heart')

print('Wrote model to', path)